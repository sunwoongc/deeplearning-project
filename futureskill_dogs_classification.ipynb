{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "futureskill-dogs-classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1t62HbwkAuCaBf409qyTJF-MojPx1JmK7",
      "authorship_tag": "ABX9TyPiRyV+g2w2G9+Aeh0j09RQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunwoongc/deeplearning-project/blob/main/futureskill_dogs_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFpjkaQ4knMj"
      },
      "source": [
        "# Dog breed Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWiEy5ziEuUK"
      },
      "source": [
        "## Naive Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C67-tC05FAmf"
      },
      "source": [
        "### 1. Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMQYH_eptBV"
      },
      "source": [
        "import scipy\n",
        "from scipy import io\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcpYBHBSeUte"
      },
      "source": [
        "### 2. Explore and load the data\n",
        "\n",
        "Load the data from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMQ08HYTfJsa"
      },
      "source": [
        "# 이미지셋을 불러옵니다.\n",
        "def load_image(filepath):\n",
        "\timage = Image.open(filepath)\n",
        "\treturn np.array(image)\n",
        "\n",
        "# 데이터 라벨링을 합니다. \n",
        "def load_label(filepath):\n",
        "\tmatdata = scipy.io.loadmat(filepath)\n",
        "\treturn matdata['file_list'], matdata['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ygnepH8FWQi"
      },
      "source": [
        "By using glob, we can access to the directory and explore the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72vQOzx1xLo2"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/stanford_dog_dataset/Images/'\n",
        "files = glob.glob(file_path + '/*')\n",
        "num_classes = len(files)\n",
        "\n",
        "num_images = 0\n",
        "for images in files:\n",
        "    num_images += len(glob.glob(images + '/*'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDkpavhLzfAt"
      },
      "source": [
        "print(f'There are total {num_images} images')\n",
        "print(f'There are total {num_classes} breeds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w5zX8we-ki"
      },
      "source": [
        "### 3. Generating dataset\n",
        "\n",
        "Since I have the both file list and label list, I choose to generate dataset by making custom function. I resize the image size to (150, 150) and make the image shape as (150,150,3), because some picture has 4 channels, (R,G,B,A) where A stands for AlphaChannel, represents transparency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQeoqDfM0_WJ"
      },
      "source": [
        "label_path = '/content/drive/MyDrive/stanford_dog_dataset/lists/file_list.mat'\n",
        "file_list, labels = load_label(label_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3l37tn0fBTT"
      },
      "source": [
        "def generate_dataset(file_list, labels):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for dir, label in tqdm(zip(file_list, labels), total=len(labels)): \n",
        "        image = load_image(file_path + dir[0][0])\n",
        "        image = cv2.resize(image, (150, 150)) ## resize\n",
        "        image = image[...,:3]\n",
        "        X.append(image)\n",
        "        Y.append(label - 1)\n",
        "    return np.array(X, dtype=np.float32), np_utils.to_categorical(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H115SHCtFu1a"
      },
      "source": [
        "It takes such a long time because Colab has to load the data on its own memory(RAM).\n",
        "\n",
        "*It can compute on data that's on the memory of GPU - 'FSDL Lecture 6'*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mYYawQ7ftJa"
      },
      "source": [
        "X, Y = generate_dataset(file_list, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwdHW-2uhRNa"
      },
      "source": [
        "print(X.shape)\n",
        "print(X.dtype)\n",
        "print(type(X))\n",
        "print(Y.shape)\n",
        "print(type(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKYscqRplEEH"
      },
      "source": [
        "### 4. Data Preprocessing\n",
        "\n",
        "In here, I only do normalize step, which divide the images by 255, for preprocessing step. Because of the lack of RAM(25.51GB), I have to normalize the data batch by batch.\n",
        "\n",
        "Here the batch_size=700 is given, by calculating MNIST dataset's size as 60000 * 28 * 28 * 1, divided by 150 * 150 * 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCelNcklDOF",
        "cellView": "code"
      },
      "source": [
        "def normalize_image_batch(data, batch_size=700):\n",
        "    for idx in tqdm(range(0, len(data), batch_size)):\n",
        "        data[idx:idx+batch_size] = data[idx:idx+batch_size] / 255.\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rYpUgvelnA3",
        "cellView": "code"
      },
      "source": [
        "X = normalize_image_batch(X, 700)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQvGpfujet6_"
      },
      "source": [
        "###5. Visualize some data\n",
        "\n",
        "To show that my 'preprocessing' works, I'll show some transformed image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tUVGBCOh7JC"
      },
      "source": [
        "def visualize_data(n: int=4) -> int:\n",
        "    fig, axs = plt.subplots(nrows = int(n/2), ncols = 2, figsize=(5,8))\n",
        "    axes = axs.ravel()\n",
        "    for i in np.arange(n):\n",
        "        num = np.random.randint(0, len(X))\n",
        "        axes[i].imshow(X[num])\n",
        "        axes[i].set_title(np.where(Y[num]==1)[0])\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qekEeXICjHSR"
      },
      "source": [
        "visualize_data(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLgWpyuTHdF0"
      },
      "source": [
        "### 6. Train-test-split\n",
        "\n",
        "For training and inferencing, I have to split the data. There is a module, `train_test_split` in `sklearn.preprocessing`. I create my own split function, but I think I can use the module too. Sometimes both method can have 'memory problem'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2st0KIpJwPY"
      },
      "source": [
        "def my_train_test_split(x, y, split_ratio=0.2, shuffle=True):\n",
        "    num_data = x.shape[0]\n",
        "    split = int(num_data * (1-split_ratio))\n",
        "    idx = np.random.permutation(num_data) if shuffle else np.arange(num_data)\n",
        "\n",
        "    x = x[idx]\n",
        "    y = y[idx]\n",
        "    x_train = x[:split, :]\n",
        "    y_train = y[:split]\n",
        "    x_test = x[split:, :]\n",
        "    y_test = y[split:]\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8jtLR6YE0Vv"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = my_train_test_split(X, Y, split_ratio=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7hYe1ZJSDT"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAqDHlzwmDbR"
      },
      "source": [
        "### 7. Train the model\n",
        "\n",
        "Here, I make my own model architecture based on CNN, but actually just copy and paste the past architecture I used for MNIST classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPZd4FN_Litm"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()\n",
        "model.add(tf.keras.Input(shape=x_train.shape[1:]))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer='l2'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(y_train.shape[-1], activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYut-GCQLyKC"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvpkklUcMK_p"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "metric_history_1 = model.fit(x_train, y_train, epochs=30, batch_size=512, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKcYGonHKbGH"
      },
      "source": [
        "###8. Loss/Accuracy Graph\n",
        "\n",
        "I plot the loss and accuracy graph by using matplotlib, and check the accuracy by counting the number of correct classified item. And it has **POOR** results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCmu6jIkMmnF"
      },
      "source": [
        "print(metric_history_1.history.keys())\n",
        "print(metric_history_1.history.keys())\n",
        "print(type(metric_history_1.history))\n",
        "print(type(metric_history_1.history['loss']))\n",
        "\n",
        "print(metric_history_1.history.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWYWXWnwqQ2b"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
        "axs = axes.ravel()\n",
        "train_acc = metric_history_1.history['accuracy']\n",
        "val_acc = metric_history_1.history['val_accuracy']\n",
        "train_loss = metric_history_1.history['loss']\n",
        "val_loss = metric_history_1.history['val_loss']\n",
        "\n",
        "axs[0].plot(train_acc, label='train_acc', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[0].plot(val_acc, label='val_acc', ls='-', color='tomato', zorder=2)\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[0].axhspan(ymin=0, ymax=0.1, facecolor='orangered', alpha=0.2)\n",
        "\n",
        "axs[1].plot(train_loss, label='train_loss', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[1].plot(val_loss, label='val_loss', ls='-', color='tomato', zorder=2)\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[1].axvspan(xmin=6.0, xmax=6.5, facecolor='orangered', alpha=0.2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "461p8P0GoXMu"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred_label = np_utils.to_categorical(np.argmax(model.predict(x_test), axis=-1), num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FACavqX56EEi"
      },
      "source": [
        "correctd_image = len(np.where((y_pred_label == y_test).all(axis=1))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZJMkq7Pw6iF"
      },
      "source": [
        "print(f'Poorly Result: Only {correctd_image} are correct out of {len(y_pred)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA7imwlKxotn"
      },
      "source": [
        "## Transfer Learning without data preprocessing (Transfer Learning but combined with above naive approch.)\n",
        "\n",
        "Since I think it'll be done just by using pre-trained model and do the same task with above, I don't use any preprocessing method and just lend the **VGG16** model to use in the same above approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eOlfELBxGGT"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16#, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVnAG4zYxvTz"
      },
      "source": [
        "base_model = VGG16(include_top=False,\n",
        "                   input_shape = (150, 150, 3),\n",
        "                   weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(base_model)\n",
        "model_2.add(GlobalAveragePooling2D())\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(2048, activation='relu'))\n",
        "model_2.add(Dense(4096, activation='relu'))\n",
        "model_2.add(Dense(num_classes, activation='softmax'))\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aGxhBVeNdWF"
      },
      "source": [
        "model_2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "metric_history_2 = model_2.fit(x_train, y_train, batch_size=512, epochs=15, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcOO0QVgNlCD"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
        "axs = axes.ravel()\n",
        "train_acc = metric_history_2.history['accuracy']\n",
        "val_acc = metric_history_2.history['val_accuracy']\n",
        "train_loss = metric_history_2.history['loss']\n",
        "val_loss = metric_history_2.history['val_loss']\n",
        "\n",
        "axs[0].plot(train_acc, label='train_acc', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[0].plot(val_acc, label='val_acc', ls='-', color='tomato', zorder=2)\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[0].axhspan(ymin=0, ymax=0.1, facecolor='orangered', alpha=0.2)\n",
        "axs[0].axhline(y=0.36, ls='--', color='dodgerblue')\n",
        "axs[0].axhline(y=0.25, ls='--', color='tomato')\n",
        "\n",
        "axs[1].plot(train_loss, label='train_loss', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[1].plot(val_loss, label='val_loss', ls='-', color='tomato', zorder=2)\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[1].axvspan(xmin=60 , xmax=60.5, facecolor='orangered', alpha=0.2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccbwcptCMTHf"
      },
      "source": [
        "It has almost the same **poor** result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkVh-_4WIOsH"
      },
      "source": [
        "## Using ImageDataGenerator to load and generate dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfPHYJ0q3fnz"
      },
      "source": [
        "###Using `flow_from_directory` method\n",
        "\n",
        "By using `flow_from_directory` method, we don't have to use the `generate_dataset` function anymore. `flow_from_directory` method returns a DirectoryIterator yielding tuples of `(x, y)` where x in a numpy array containing a batch of images with shape `(batch_size, *target_size, channels)`, and `y` is a numpy array of corresponding labels.\n",
        "\n",
        "It is really comfortable that we don't have to generate dataset explicitly, since it generates **batches of augmented data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXQwxm8vEbbv"
      },
      "source": [
        "####1. Transfer Learning - VGG16 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFuHWrtWySOL"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbqZcfG64nTl"
      },
      "source": [
        "Since I'm going to use pre-trained model, it is good to use their own preprocessing method, `preprocessing_function = preprocess_input` takes that role, and `preprocess_input` is imported from `keras.applications.vgg16`.  Thie can be applied to other pre-trained model as well.\n",
        "\n",
        "We can simply used rescaling factor only, e.g. `X = X / 255.`, but better training performance, it is recommended to use `preprocess_input`.\n",
        "\n",
        "`preprocess_input` has parameter `mode`, and it is one of \"caffe\", \"tf\" or \"torch\" and each mode has different method of preprocessing. [(docs)](https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWneGuOWyy-u"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    # rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function = preprocess_input,\n",
        "    validation_split=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA1rupxFwMMn"
      },
      "source": [
        "dir = '/content/drive/MyDrive/stanford_dog_dataset/Images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqtladgXy9l9"
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(100, 100),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEgjk_g80Q5z"
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(100, 100),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    subset='validation'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4GsiYIt6hdW"
      },
      "source": [
        "base_model = VGG16(include_top=False,\n",
        "                   input_shape = (100, 100, 3),\n",
        "                   weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(120, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiysd2M14WwV"
      },
      "source": [
        "opt = Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKVugod84ZR5"
      },
      "source": [
        "history = model.fit(train_generator, \n",
        "                    validation_data = test_generator,\n",
        "                    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8evM_QdI5BK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
        "axs = axes.ravel()\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "axs[0].plot(train_acc, label='train_acc', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[0].plot(val_acc, label='val_acc', ls='-', color='tomato', zorder=2)\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "# axs[0].axhspan(ymin=0, ymax=0.1, facecolor='orangered', alpha=0.2)\n",
        "# axs[0].axhline(y=0.36, ls='--', color='dodgerblue')\n",
        "# axs[0].axhline(y=0.25, ls='--', color='tomato')\n",
        "\n",
        "axs[1].plot(train_loss, label='train_loss', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[1].plot(val_loss, label='val_loss', ls='-', color='tomato', zorder=2)\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "# axs[1].axvspan(xmin=80 , xmax=80.5, facecolor='orangered', alpha=0.2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDbD7gI4X520"
      },
      "source": [
        "It isn't achieved that much accuracy since I just train it for 10 epochs, but the trend looks reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsgHikrTwnvv"
      },
      "source": [
        "#### Transfer Learning - EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7tIIX1p8zcU"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGuZJanqwmiK"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    # rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    preprocessing_function = preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=.2)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1./255, validation_split=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC7K7OZiwmiW"
      },
      "source": [
        "dir = '/content/drive/MyDrive/stanford_dog_dataset/Images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdniYf5twmiW"
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIKdVt8vwmiW"
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    subset='validation'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lglg9TVVwzgv"
      },
      "source": [
        "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1280, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(120, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckz5W7UpxZsp"
      },
      "source": [
        "from tensorflow.keras.models import *\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "# for layer in model.layers[-2:]: ## added \n",
        "#     layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-DeYiEixjR9"
      },
      "source": [
        "optimizer = Adam(lr=0.0001)\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGN-z53zxz58"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXptdJF6sHuD"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmLmRuFByIDE"
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpfEScKpy7NF"
      },
      "source": [
        "history_2 = model.fit(train_generator,\n",
        "                      steps_per_epoch = len(train_generator), \n",
        "                      validation_data = test_generator,\n",
        "                      validation_steps = len(test_generator),\n",
        "                      epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_FTS5RWgXQ9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
        "axs = axes.ravel()\n",
        "train_acc = history_2.history['accuracy']\n",
        "val_acc = history_2.history['val_accuracy']\n",
        "train_loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "\n",
        "axs[0].plot(train_acc, label='train_acc', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[0].plot(val_acc, label='val_acc', ls='-', color='tomato', zorder=2)\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "# axs[0].axhspan(ymin=0, ymax=0.1, facecolor='orangered', alpha=0.2)\n",
        "# axs[0].axhline(y=0.36, ls='--', color='dodgerblue')\n",
        "# axs[0].axhline(y=0.25, ls='--', color='tomato')\n",
        "\n",
        "axs[1].plot(train_loss, label='train_loss', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[1].plot(val_loss, label='val_loss', ls='-', color='tomato', zorder=2)\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "# axs[1].axvspan(xmin=80 , xmax=80.5, facecolor='orangered', alpha=0.2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSRh987Svlb0"
      },
      "source": [
        "#### Transfer Learning - ResNet50\n",
        "According to the above experiment, I realized that all that 15 epochs are not needed. What if tranining accuracy become about 95% with just 3 epochs(also validation accuracy)? Then all the leftover epochs are redundant.\n",
        "\n",
        "So I decide to put some **Callbacks**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHZyCzLUhNF"
      },
      "source": [
        "### Downloading dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CTbf6R4VKNn"
      },
      "source": [
        "root_path = 'gdrive/My Drive/stanford_dog_dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizUkqhjrzXQ"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import decode_predictions, ResNet50, preprocess_input\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjStLpA_h1uJ"
      },
      "source": [
        "checkpoint_filepath = '/content/gdrive/MyDrive/ResNet50_dog_breed_classifier.h5'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5NVPSBXjJlb"
      },
      "source": [
        "import datetime as dt\n",
        "tensorboard = TensorBoard(log_dir=\"/content/gdrive/MyDrive/logs-\"+dt.datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=False,\n",
        "                          update_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naCWabQxkqC_"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='accuracy',\n",
        "                          min_delta=0.0001,\n",
        "                          patience=20,\n",
        "                          verbose=1,\n",
        "                          mode='auto',\n",
        "                          baseline=None,\n",
        "                          restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMg5KpWYmcc9"
      },
      "source": [
        "import numpy as np\n",
        "reducelr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                             factor=np.sqrt(.1),\n",
        "                             patience=5,\n",
        "                             verbose=1,\n",
        "                             mode='auto',\n",
        "                             min_delta=0.0001,\n",
        "                             cooldown=0,\n",
        "                             min_lr=0.0000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re7uVnOHpidp"
      },
      "source": [
        "def epoch_begin(epoch, logs):\n",
        "    print(f\"Learning rate is: {K.eval(model.optimizer.lr)}\")\n",
        "\n",
        "def epoch_end(epoch, logs):\n",
        "    print(f\"End of epoch {epoch}, Learning rate is: {K.eval(model.optimizer.lr)}\")\n",
        "\n",
        "def train_begin(logs):\n",
        "    print(\"Training begins\")\n",
        "\n",
        "lambdacallback = LambdaCallback(on_epoch_begin=epoch_begin,\n",
        "                                on_epoch_end=epoch_end,\n",
        "                                on_train_begin=train_begin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2bPgdQ5v6N7"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    # rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    preprocessing_function = preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=.2)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1./255, validation_split=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDx_d5Ttv6N7"
      },
      "source": [
        "dir = '/content/gdrive/MyDrive/stanford_dog_dataset/Images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OICOXlv6v6N8"
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT7irkZRv6N9"
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    directory=dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    subset='validation'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkCezYr6v6N9"
      },
      "source": [
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1280, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(120, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx9FIhOrv6N9"
      },
      "source": [
        "from tensorflow.keras.models import *\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "# for layer in model.layers[-2:]: ## added \n",
        "#     layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_K24XPtv6N-"
      },
      "source": [
        "optimizer = Adam(lr=0.0001)\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc9UcAqLv6N-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1qYfCvv58_"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZoA1CHgweoi"
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgzHSnzweoj"
      },
      "source": [
        "history_3 = model.fit(train_generator,\n",
        "                      validation_data = test_generator,\n",
        "                      epochs=15,\n",
        "                      callbacks=[reducelr, earlystop, lambdacallback, tensorboard, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zYLXfkcZQFt"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
        "axs = axes.ravel()\n",
        "train_acc = history_3.history['accuracy']\n",
        "val_acc = history_3.history['val_accuracy']\n",
        "train_loss = history_3.history['loss']\n",
        "val_loss = history_3.history['val_loss']\n",
        "\n",
        "axs[0].plot(train_acc, label='train_acc', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[0].plot(val_acc, label='val_acc', ls='-', color='tomato', zorder=2)\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(train_loss, label='train_loss', ls='--', color='dodgerblue', zorder=2)\n",
        "axs[1].plot(val_loss, label='val_loss', ls='-', color='tomato', zorder=2)\n",
        "axs[1].set_title('Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Umd1CNir-D"
      },
      "source": [
        "### Kaggle's help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uckMpvgbZrl5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "image_num = np.random.randint(0, test_generator.samples)\n",
        "name = test_generator.filepaths[image_num]\n",
        "plt.imshow(mpimg.imread(name))\n",
        "\n",
        "img = Image.open(name).resize((224, 224))\n",
        "probabilites = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\n",
        "breed_list = tuple(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()))\n",
        "\n",
        "for i in probabilites[0].argsort()[-5:][::-1]:\n",
        "    print(probabilites[0][i], \": \", breed_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kocdpb1eZQFx"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator, steps=len(test_generator))\n",
        "y = np.argmax(predictions, axis=1)\n",
        "\n",
        "print('Classification Report')\n",
        "cr = classification_report(y_true=test_generator.classes, y_pred=y, target_names=test_generator.class_indices)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCtB3oLZZQFy"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "cm = confusion_matrix(test_generator.classes, y)\n",
        "df = pd.DataFrame(cm, columns=test_generator.class_indices)\n",
        "plt.figure(figsize=(80,80))\n",
        "sns.heatmap(df, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHg0a47pesB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}